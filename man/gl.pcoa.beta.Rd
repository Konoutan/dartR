% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/gl.pcoa_beta.r
\name{gl.pcoa.beta}
\alias{gl.pcoa.beta}
\title{PCoA ordination applied to genotypes in a genlight object or to a distance matrix}
\usage{
gl.pcoa.beta(x, nfactors = 5, verbose = 2)
}
\arguments{
\item{x}{-- name of the genlight object containing the SNP data or a distance matrix of type dist [required]}

\item{nfactors}{-- number of axes to retain in the output of factor scores.}

\item{verbose}{-- specify the level of verbosity: 0, silent, fatal errors only; 1, flag function begin and end; 2, progress log ; 3, progress and results summary; 5, full report [default 2]}
}
\value{
An object of class pcoa containing the eigenvalues and factor scores
}
\description{
This function takes the data on SNP genotypes for individuals and undertakes a Gower Principal Coordinates Ordination using (a) Euclidean distance calculated from
data in the original genlight \{adegenet\} object (entity x attribute matrix) OR (b) drawing upon a distance matrix generated with gl.dist.pop() 
or gl.dist.ind(). By providing the function with a distance matrix, technically any distance matrix can be represented in an ordinated space.
}
\details{
The function is essentially a wrapper for pcoa \{ape\} with default settings apart from those specified as parameters in this 
function.

There are three major sources of stress in a reduced-reprentation of distances or dissimilarities among entities using PCoA. By far the greatest
source comes from the decision to select only the top two or three axes from the ordinated set of axes derived from the PCoA. The representation of
the entities such a heavily reduced space will not faithfully represent the distances in the input distance matrix simply because of the loss of information
in deeper informative dimensions. For this reason, it is not sensible to be too precious about managing the other two sources of stress in
the visual representation.

The second source of stress in a PCoA is the choice of distance metric or dissimilarity measure. While any 
distance or dissimilarity matrix can be represented in an ordinated space, the distances between entities can befaithfully represented 
in that space (that is, without stress) only if the distances are metric. Furthermore, for distances between entities to be faithfully 
represented in a rigid Cartesian space, the distance measure needs to be Euclidean. If this is not the case, 
the distances between the entities in the ordinated visualized space will not exactly represent the distances in the input matrix 
(stress will be non-zero). This source of stress will be evident as negative eigenvalues in the deeper dimensions.

A third source of stress arises from having a sparse dataset, one with missing values. If the original data matrix is not fully populated, that is, 
if there are missing values, then even a Euclidean distance matrix will not necessarily be 'positive definite'. It follows that some of the eigenvalues 
may be negative, even though the distance metric is Euclidean. This issue is exacerbated when the number of loci greatly exceeds the number of individuals, 
as is typically the case when working with SNP data. The impact of missing values can be minimized by stringently filtering on Call Rate, albeit with 
loss of data. An alternative is given in a paper "Honey, I shrunk the sample covariance matrix" and more recently by Ledoit and Wolf (2018), but their 
approach has not been implemented here.

The good news is that, unless the sum of the negative eigenvalues, arising from a non-Euclidean distance measure or from missing values, approaches those 
of the final PCoA axes to be displayed, the distortion is probably of no practical consequence and certainly not comparable to the stress arising from
selecting only two or three final dimensions out of several informative dimensions for the visual representation.

Two diagnostic plots are produced. The first is a Scree Plot, showing the percentage variation explained by each of the PCoA axes, for those axes that 
explain more than the original variables (loci) on average. That is, only informative axes are displayed. The scree plot informs the number of dimensions
to be retained in the visual summaries. As a rule of thumb, axes with more than 10% of variation explained should be included.

The second graph shows the distribution of eigenvalues for the remaining uninformative (noise) axes, including those with negative eigenvalues. 
Action is required if the negative eigenvalues are dominant, their sum approaching in magnitude the eigenvalues for axes selected for 
the final visual solution. That action would involve more stringent filtering on call rate and then repeating the PCoA.

Output is a pcoa object conforming to the object generated by ape:pcoa but with only the following retained.
 $values
   Eigenvalues	-- All eigenvalues (positive, null, negative).
   Relative_eig -- Relative eigenvalues.
 $vectors 
   Scores (coefficients) for each individual
}
\examples{
pcoa <- gl.pcoa.beta(testset.gl)
}
\references{
Gower, J. C. (1966) Some distance properties of latent root and vector methods used in multivariate analysis. Biometrika, 53, 325â€“338.
Ledoit, O. and Wolf, M. (2018). Analytical Nonlinear Shrinkage of Large-Dimensional Covariance Matrices. University of Zurich, Department of Economics, Working Paper No. 264, Revised version. Available at SSRN: https://ssrn.com/abstract=3047302 or http://dx.doi.org/10.2139/ssrn.3047302
}
\author{
Arthur Georges (Post to \url{https://groups.google.com/d/forum/dartr})
}
